{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import  torch\n",
    "import  numpy as np\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imgdataset(data.Dataset):\n",
    "    def __init__(self, img_folder, ann_data, img_size=64, transform=[]):\n",
    "        self.img_folder = img_folder\n",
    "        self.ann_data = ann_data\n",
    "        self.transform = transform\n",
    "\n",
    "        self.all_ann_smiling = {}\n",
    "        with open(ann_data, 'r') as f:\n",
    "            rows = csv.DictReader(f)\n",
    "            for row in rows:\n",
    "                self.all_ann_smiling[row['image_name']] = int(float(row['Smiling']))\n",
    "        \n",
    "        self.all_img_path = []\n",
    "        all_img_file = os.listdir(img_folder)\n",
    "        for file_name in all_img_file:\n",
    "            self.all_img_path.append(file_name)\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.all_img_path)   \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img_file_name = self.all_img_path[index]\n",
    "        label = self.all_ann_smiling[img_file_name]\n",
    "        \n",
    "        img_path = os.path.join(self.img_folder, img_file_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = self.BGR2RGB(img)\n",
    "        #img = self.random_flip(img)\n",
    "        for t in self.transform:\n",
    "            img = t(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "\n",
    "    def BGR2RGB(self,img):\n",
    "        return cv2.cvtColor(img,cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, figsize=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d( 101, figsize * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(figsize * 8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(figsize * 8, figsize * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(figsize * 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(figsize * 4, figsize * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(figsize * 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(figsize * 2, figsize, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(figsize),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(figsize, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "            \n",
    "    def forward(self, X):\n",
    "        output = self.decoder(X)/2.0+0.5\n",
    "        return output\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, figsize=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(3, figsize, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(figsize, figsize * 2, 4, 2, 1),\n",
    "            nn.BatchNorm2d(figsize * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(figsize * 2, figsize * 4, 4, 2, 1),\n",
    "            nn.BatchNorm2d(figsize * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(figsize * 4, figsize * 8, 4, 2, 1),\n",
    "            nn.BatchNorm2d(figsize * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(figsize * 8, figsize *1, 4, 1, 0),\n",
    "        )\n",
    "        self.fc_dis = nn.Linear(figsize *1, 1)\n",
    "        self.fc_aux = nn.Linear(figsize *1, 1) \n",
    "       \n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        decode_output = self.decoder(X)\n",
    "\n",
    "        flat = decode_output.view(-1,64)\n",
    "        fc_dis = self.fc_dis(flat)\n",
    "        fc_aux = self.fc_aux(flat)\n",
    "        \n",
    "        realfake = self.sigmoid(fc_dis)\n",
    "        classes = self.sigmoid(fc_aux)\n",
    "        \n",
    "        return realfake, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed((38))\n",
    "torch.manual_seed(38)\n",
    "up = np.ones(10)\n",
    "down = np.zeros(10)\n",
    "fixed_class = np.hstack((up,down))\n",
    "fixed_class = torch.from_numpy(fixed_class).view(20,1,1,1).type(torch.FloatTensor)\n",
    "fixed_noise = torch.randn(10, 100, 1, 1)\n",
    "fixed_noise = torch.cat((fixed_noise,fixed_noise))\n",
    "fixed_input = Variable(torch.cat((fixed_noise, fixed_class),1)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_img = \"../../../hw3_data/face/train\"\n",
    "csv_data_path = \"../../../hw3_data/face/train.csv\"\n",
    "img_size = 64\n",
    "train_data = Imgdataset(train_file_img, csv_data_path, img_size, transform=[transforms.ToTensor()])\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "                                dataset=train_data,\n",
    "                                batch_size=64,\n",
    "                                shuffle=True,\n",
    "                                num_workers=8\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "training D Loss: 0.9111850221633911\n",
      "training G Loss: 1.181247861289978\n",
      "D_real_dis_acc: 34.5728\n",
      "D_fake_dis_acc: 35.4704\n",
      "D_real_aux_loss: 22.557610455322266\n",
      "D_fake_aux_loss: 4.1843146078109745\n",
      "Epoch: 2\n",
      "training D Loss: 0.823833782863617\n",
      "training G Loss: 0.9617933699607849\n",
      "D_real_dis_acc: 35.4304\n",
      "D_fake_dis_acc: 37.7264\n",
      "D_real_aux_loss: 17.300579410552977\n",
      "D_fake_aux_loss: 1.1598817717552186\n",
      "Epoch: 3\n",
      "training D Loss: 0.8006055232048035\n",
      "training G Loss: 0.9560264995574951\n",
      "D_real_dis_acc: 36.6624\n",
      "D_fake_dis_acc: 38.1808\n",
      "D_real_aux_loss: 15.276254290771485\n",
      "D_fake_aux_loss: 1.1510674974441528\n",
      "Epoch: 4\n",
      "training D Loss: 0.7910450421333313\n",
      "training G Loss: 0.9165473872184754\n",
      "D_real_dis_acc: 36.7824\n",
      "D_fake_dis_acc: 37.9552\n",
      "D_real_aux_loss: 14.204255059051514\n",
      "D_fake_aux_loss: 1.243900582385063\n",
      "Epoch: 5\n",
      "training D Loss: 0.7742502745628357\n",
      "training G Loss: 0.948410243177414\n",
      "D_real_dis_acc: 38.1536\n",
      "D_fake_dis_acc: 38.8032\n",
      "D_real_aux_loss: 13.27527667617798\n",
      "D_fake_aux_loss: 1.289431622505188\n",
      "Epoch: 6\n",
      "training D Loss: 0.7546045879364014\n",
      "training G Loss: 1.0072149905204772\n",
      "D_real_dis_acc: 39.8208\n",
      "D_fake_dis_acc: 40.1136\n",
      "D_real_aux_loss: 12.359730067443847\n",
      "D_fake_aux_loss: 1.4018687752008439\n",
      "Epoch: 7\n",
      "training D Loss: 0.7152330592155457\n",
      "training G Loss: 1.1331177505016328\n",
      "D_real_dis_acc: 42.0464\n",
      "D_fake_dis_acc: 42.4608\n",
      "D_real_aux_loss: 11.479348086166382\n",
      "D_fake_aux_loss: 1.4585862562179566\n",
      "Epoch: 8\n",
      "training D Loss: 0.6755623692512512\n",
      "training G Loss: 1.2870056519508362\n",
      "D_real_dis_acc: 44.3856\n",
      "D_fake_dis_acc: 44.5936\n",
      "D_real_aux_loss: 10.535733029174805\n",
      "D_fake_aux_loss: 1.4998538707017899\n",
      "Epoch: 9\n",
      "training D Loss: 0.6210714679718018\n",
      "training G Loss: 1.4850415566444397\n",
      "D_real_dis_acc: 46.4224\n",
      "D_fake_dis_acc: 46.4768\n",
      "D_real_aux_loss: 9.552663043498994\n",
      "D_fake_aux_loss: 1.446695471048355\n",
      "Epoch: 10\n",
      "training D Loss: 0.554435288143158\n",
      "training G Loss: 1.7285911168575288\n",
      "D_real_dis_acc: 48.9872\n",
      "D_fake_dis_acc: 49.3376\n",
      "D_real_aux_loss: 8.386058266830444\n",
      "D_fake_aux_loss: 1.5451770762443542\n",
      "Epoch: 11\n",
      "training D Loss: 0.5152614761352539\n",
      "training G Loss: 1.9455145129203797\n",
      "D_real_dis_acc: 50.408\n",
      "D_fake_dis_acc: 50.52\n",
      "D_real_aux_loss: 7.315725969886779\n",
      "D_fake_aux_loss: 1.480984745466709\n",
      "Epoch: 12\n",
      "training D Loss: 0.4741224746465683\n",
      "training G Loss: 2.1510505098342896\n",
      "D_real_dis_acc: 51.9184\n",
      "D_fake_dis_acc: 52.0592\n",
      "D_real_aux_loss: 6.508310074234009\n",
      "D_fake_aux_loss: 1.5688912767648697\n",
      "Epoch: 13\n",
      "training D Loss: 0.4362148660182953\n",
      "training G Loss: 2.340305304145813\n",
      "D_real_dis_acc: 52.8784\n",
      "D_fake_dis_acc: 53.3472\n",
      "D_real_aux_loss: 5.867957217311859\n",
      "D_fake_aux_loss: 1.6007262970209122\n",
      "Epoch: 14\n",
      "training D Loss: 0.41078331990242006\n",
      "training G Loss: 2.533063697195053\n",
      "D_real_dis_acc: 53.5552\n",
      "D_fake_dis_acc: 54.0208\n",
      "D_real_aux_loss: 5.098671131038666\n",
      "D_fake_aux_loss: 1.5927876744687557\n",
      "Epoch: 15\n",
      "learning rate change!\n",
      "training D Loss: 0.21067182631492615\n",
      "training G Loss: 2.7464745054721833\n",
      "D_real_dis_acc: 61.0896\n",
      "D_fake_dis_acc: 61.144\n",
      "D_real_aux_loss: 2.9226067439556123\n",
      "D_fake_aux_loss: 1.2286594326108695\n",
      "Epoch: 16\n",
      "training D Loss: 0.21581940624713897\n",
      "training G Loss: 3.242384949874878\n",
      "D_real_dis_acc: 59.9472\n",
      "D_fake_dis_acc: 59.872\n",
      "D_real_aux_loss: 2.572380527496338\n",
      "D_fake_aux_loss: 1.4553645984828472\n",
      "Epoch: 17\n",
      "training D Loss: 0.21645019232034685\n",
      "training G Loss: 3.4902044620990753\n",
      "D_real_dis_acc: 59.592\n",
      "D_fake_dis_acc: 59.576\n",
      "D_real_aux_loss: 2.287558998966217\n",
      "D_fake_aux_loss: 1.5121012308329345\n",
      "Epoch: 18\n",
      "training D Loss: 0.21355574499964713\n",
      "training G Loss: 3.742936875963211\n",
      "D_real_dis_acc: 59.576\n",
      "D_fake_dis_acc: 59.4736\n",
      "D_real_aux_loss: 2.0963819375514983\n",
      "D_fake_aux_loss: 1.4896289836481214\n",
      "Epoch: 19\n",
      "training D Loss: 0.2182336760044098\n",
      "training G Loss: 3.8353397974014283\n",
      "D_real_dis_acc: 59.7328\n",
      "D_fake_dis_acc: 59.5392\n",
      "D_real_aux_loss: 1.9430936660051346\n",
      "D_fake_aux_loss: 1.496551182755828\n",
      "Epoch: 20\n",
      "training D Loss: 0.1946965492606163\n",
      "training G Loss: 3.9762898045539856\n",
      "D_real_dis_acc: 60.1072\n",
      "D_fake_dis_acc: 59.9856\n",
      "D_real_aux_loss: 1.8049907397627831\n",
      "D_fake_aux_loss: 1.4170682729832829\n",
      "Epoch: 21\n",
      "training D Loss: 0.21028139127492904\n",
      "training G Loss: 4.031736552190781\n",
      "D_real_dis_acc: 59.5664\n",
      "D_fake_dis_acc: 59.3264\n",
      "D_real_aux_loss: 1.6737136740684508\n",
      "D_fake_aux_loss: 1.3931274614863098\n",
      "Epoch: 22\n",
      "training D Loss: 0.2023498852431774\n",
      "training G Loss: 4.223570285701752\n",
      "D_real_dis_acc: 59.7648\n",
      "D_fake_dis_acc: 59.5088\n",
      "D_real_aux_loss: 1.6219736205935478\n",
      "D_fake_aux_loss: 1.4604658940896391\n",
      "Epoch: 23\n",
      "training D Loss: 0.19209916285276413\n",
      "training G Loss: 4.216626885080338\n",
      "D_real_dis_acc: 59.9952\n",
      "D_fake_dis_acc: 59.9312\n",
      "D_real_aux_loss: 1.6284422793626785\n",
      "D_fake_aux_loss: 1.662568334530294\n",
      "Epoch: 24\n",
      "training D Loss: 0.19936572234034539\n",
      "training G Loss: 4.387601000976563\n",
      "D_real_dis_acc: 59.9392\n",
      "D_fake_dis_acc: 59.7072\n",
      "D_real_aux_loss: 1.6813659926772118\n",
      "D_fake_aux_loss: 1.597402646560967\n",
      "Epoch: 25\n",
      "training D Loss: 0.22212956427931785\n",
      "training G Loss: 4.28989056596756\n",
      "D_real_dis_acc: 59.128\n",
      "D_fake_dis_acc: 58.9808\n",
      "D_real_aux_loss: 1.5305576189041137\n",
      "D_fake_aux_loss: 1.3592708857022227\n",
      "Epoch: 26\n",
      "training D Loss: 0.19356961864233016\n",
      "training G Loss: 4.331138893222809\n",
      "D_real_dis_acc: 59.9872\n",
      "D_fake_dis_acc: 59.7632\n",
      "D_real_aux_loss: 1.4653528715133668\n",
      "D_fake_aux_loss: 1.371161536989361\n",
      "Epoch: 27\n",
      "training D Loss: 0.2117676164150238\n",
      "training G Loss: 4.40186653137207\n",
      "D_real_dis_acc: 59.6\n",
      "D_fake_dis_acc: 59.4192\n",
      "D_real_aux_loss: 1.5022987171530724\n",
      "D_fake_aux_loss: 1.4115471769098193\n",
      "Epoch: 28\n",
      "training D Loss: 0.18332748342752456\n",
      "training G Loss: 4.392025698804855\n",
      "D_real_dis_acc: 60.2592\n",
      "D_fake_dis_acc: 60.0848\n",
      "D_real_aux_loss: 1.419711469015479\n",
      "D_fake_aux_loss: 1.496149341198802\n",
      "Epoch: 29\n",
      "training D Loss: 0.204114609760046\n",
      "training G Loss: 4.440834582138062\n",
      "D_real_dis_acc: 59.6384\n",
      "D_fake_dis_acc: 59.4736\n",
      "D_real_aux_loss: 1.4801881462097168\n",
      "D_fake_aux_loss: 1.6469443739060312\n",
      "Epoch: 30\n",
      "training D Loss: 0.20629536886811256\n",
      "training G Loss: 4.497701907920837\n",
      "D_real_dis_acc: 59.7024\n",
      "D_fake_dis_acc: 59.48\n",
      "D_real_aux_loss: 1.3800758287727832\n",
      "D_fake_aux_loss: 1.5038381337147206\n",
      "Epoch: 31\n",
      "training D Loss: 0.20154249420464038\n",
      "training G Loss: 4.471611239624023\n",
      "D_real_dis_acc: 59.816\n",
      "D_fake_dis_acc: 59.5872\n",
      "D_real_aux_loss: 1.3004801860034465\n",
      "D_fake_aux_loss: 1.5132675482042133\n",
      "Epoch: 32\n",
      "training D Loss: 0.19129581509828567\n",
      "training G Loss: 4.528449628829956\n",
      "D_real_dis_acc: 60.016\n",
      "D_fake_dis_acc: 59.864\n",
      "D_real_aux_loss: 1.487587557053566\n",
      "D_fake_aux_loss: 1.5474923539035021\n",
      "Epoch: 33\n",
      "training D Loss: 0.2012796211451292\n",
      "training G Loss: 4.6017909067630764\n",
      "D_real_dis_acc: 59.6848\n",
      "D_fake_dis_acc: 59.4848\n",
      "D_real_aux_loss: 1.3099270342707634\n",
      "D_fake_aux_loss: 1.3115056621059775\n",
      "Epoch: 34\n",
      "training D Loss: 0.18533178835511208\n",
      "training G Loss: 4.611716900730133\n",
      "D_real_dis_acc: 60.1472\n",
      "D_fake_dis_acc: 59.8992\n",
      "D_real_aux_loss: 1.2554376711070538\n",
      "D_fake_aux_loss: 1.3221727586802094\n",
      "Epoch: 35\n",
      "training D Loss: 0.17780480837225915\n",
      "training G Loss: 4.641152234125137\n",
      "D_real_dis_acc: 60.52\n",
      "D_fake_dis_acc: 60.1888\n",
      "D_real_aux_loss: 1.2860443462491036\n",
      "D_fake_aux_loss: 1.2847804658843205\n",
      "Epoch: 36\n",
      "training D Loss: 0.2087513300716877\n",
      "training G Loss: 4.723684991514682\n",
      "D_real_dis_acc: 59.6432\n",
      "D_fake_dis_acc: 59.3424\n",
      "D_real_aux_loss: 1.208688116812706\n",
      "D_fake_aux_loss: 1.334126102856826\n",
      "Epoch: 37\n",
      "training D Loss: 0.16688528200387956\n",
      "training G Loss: 4.79799244389534\n",
      "D_real_dis_acc: 60.7696\n",
      "D_fake_dis_acc: 60.456\n",
      "D_real_aux_loss: 1.2563937224656343\n",
      "D_fake_aux_loss: 1.3928651333503426\n",
      "Epoch: 38\n",
      "training D Loss: 0.2220254040300846\n",
      "training G Loss: 4.7626532241344455\n",
      "D_real_dis_acc: 59.592\n",
      "D_fake_dis_acc: 59.376\n",
      "D_real_aux_loss: 1.3844014280200005\n",
      "D_fake_aux_loss: 1.3732713825624436\n",
      "Epoch: 39\n",
      "training D Loss: 0.15524577266275882\n",
      "training G Loss: 4.856528403186798\n",
      "D_real_dis_acc: 60.9344\n",
      "D_fake_dis_acc: 60.6688\n",
      "D_real_aux_loss: 1.1601954982042313\n",
      "D_fake_aux_loss: 1.4741024804443121\n",
      "Epoch: 40\n",
      "training D Loss: 0.2102111636966467\n",
      "training G Loss: 4.8470560894489285\n",
      "D_real_dis_acc: 59.6608\n",
      "D_fake_dis_acc: 59.3648\n",
      "D_real_aux_loss: 1.311698229199648\n",
      "D_fake_aux_loss: 1.3356306722473819\n",
      "Epoch: 41\n",
      "training D Loss: 0.19114738446474075\n",
      "training G Loss: 4.804445272874832\n",
      "D_real_dis_acc: 60.36\n",
      "D_fake_dis_acc: 59.9872\n",
      "D_real_aux_loss: 1.1655685614585876\n",
      "D_fake_aux_loss: 1.2615587380097248\n",
      "Epoch: 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training D Loss: 0.15181630113720893\n",
      "training G Loss: 4.9179452699661255\n",
      "D_real_dis_acc: 61.0512\n",
      "D_fake_dis_acc: 60.8368\n",
      "D_real_aux_loss: 1.0575666549295186\n",
      "D_fake_aux_loss: 1.2354019808603451\n",
      "Epoch: 43\n",
      "training D Loss: 0.19215094296336174\n",
      "training G Loss: 4.95041768527031\n",
      "D_real_dis_acc: 60.0352\n",
      "D_fake_dis_acc: 59.7808\n",
      "D_real_aux_loss: 1.182758560037613\n",
      "D_fake_aux_loss: 1.3970985364573076\n",
      "Epoch: 44\n",
      "training D Loss: 0.15954525125622748\n",
      "training G Loss: 4.998869431304931\n",
      "D_real_dis_acc: 60.7664\n",
      "D_fake_dis_acc: 60.5488\n",
      "D_real_aux_loss: 1.0669844166755675\n",
      "D_fake_aux_loss: 1.2383738982167094\n",
      "Epoch: 45\n",
      "training D Loss: 0.18154515961110593\n",
      "training G Loss: 5.023114916038513\n",
      "D_real_dis_acc: 60.16\n",
      "D_fake_dis_acc: 59.7568\n",
      "D_real_aux_loss: 1.1594472771823405\n",
      "D_fake_aux_loss: 1.3741188625900076\n",
      "Epoch: 46\n",
      "training D Loss: 0.17877074747383595\n",
      "training G Loss: 5.123829780054092\n",
      "D_real_dis_acc: 60.2528\n",
      "D_fake_dis_acc: 60.0912\n",
      "D_real_aux_loss: 1.2472111391991376\n",
      "D_fake_aux_loss: 1.4755810944546015\n",
      "Epoch: 47\n",
      "training D Loss: 0.17692905911505222\n",
      "training G Loss: 5.087891048961878\n",
      "D_real_dis_acc: 60.504\n",
      "D_fake_dis_acc: 60.2288\n",
      "D_real_aux_loss: 1.186463739490509\n",
      "D_fake_aux_loss: 1.4282812389396131\n",
      "Epoch: 48\n",
      "training D Loss: 0.1532997891128063\n",
      "training G Loss: 5.054244760227204\n",
      "D_real_dis_acc: 61.048\n",
      "D_fake_dis_acc: 60.7872\n",
      "D_real_aux_loss: 0.9890245589852333\n",
      "D_fake_aux_loss: 1.1578736910860985\n",
      "Epoch: 49\n",
      "training D Loss: 0.18020259725153445\n",
      "training G Loss: 5.2539134421348574\n",
      "D_real_dis_acc: 60.2944\n",
      "D_fake_dis_acc: 59.952\n",
      "D_real_aux_loss: 1.1512525455117226\n",
      "D_fake_aux_loss: 1.3382935337737203\n",
      "Epoch: 50\n",
      "training D Loss: 0.16095731145441533\n",
      "training G Loss: 5.259253737282753\n",
      "D_real_dis_acc: 60.8992\n",
      "D_fake_dis_acc: 60.6224\n",
      "D_real_aux_loss: 1.1793834200710058\n",
      "D_fake_aux_loss: 1.4174341572457925\n",
      "Epoch: 51\n",
      "training D Loss: 0.16765068735778332\n",
      "training G Loss: 5.193078121757507\n",
      "D_real_dis_acc: 60.744\n",
      "D_fake_dis_acc: 60.3808\n",
      "D_real_aux_loss: 1.1832871705651282\n",
      "D_fake_aux_loss: 1.4934374820820988\n",
      "Epoch: 52\n",
      "training D Loss: 0.15060273930728435\n",
      "training G Loss: 5.3609112928390505\n",
      "D_real_dis_acc: 61.0512\n",
      "D_fake_dis_acc: 60.6848\n",
      "D_real_aux_loss: 1.0793707172259688\n",
      "D_fake_aux_loss: 1.4531122290750966\n",
      "Epoch: 53\n",
      "training D Loss: 0.18506999359726906\n",
      "training G Loss: 5.26830118227005\n",
      "D_real_dis_acc: 60.256\n",
      "D_fake_dis_acc: 59.9664\n",
      "D_real_aux_loss: 1.1509980977833272\n",
      "D_fake_aux_loss: 1.4828885927788913\n",
      "Epoch: 54\n",
      "training D Loss: 0.1525225777745247\n",
      "training G Loss: 5.301928649139405\n",
      "D_real_dis_acc: 61.0128\n",
      "D_fake_dis_acc: 60.6832\n",
      "D_real_aux_loss: 1.1313951443105936\n",
      "D_fake_aux_loss: 1.358001700773649\n",
      "Epoch: 55\n",
      "training D Loss: 0.17710750749111176\n",
      "training G Loss: 5.401191340470314\n",
      "D_real_dis_acc: 60.3824\n",
      "D_fake_dis_acc: 60.168\n",
      "D_real_aux_loss: 0.974973884549737\n",
      "D_fake_aux_loss: 1.197121783753857\n",
      "Epoch: 56\n",
      "training D Loss: 0.15466497192531825\n",
      "training G Loss: 5.38278078212738\n",
      "D_real_dis_acc: 60.8608\n",
      "D_fake_dis_acc: 60.5504\n",
      "D_real_aux_loss: 0.9763949671417474\n",
      "D_fake_aux_loss: 1.2614847138751297\n",
      "Epoch: 57\n",
      "training D Loss: 0.1416811430811882\n",
      "training G Loss: 5.385777634906769\n",
      "D_real_dis_acc: 61.1184\n",
      "D_fake_dis_acc: 60.8752\n",
      "D_real_aux_loss: 0.9704814730167389\n",
      "D_fake_aux_loss: 1.2177893005076796\n",
      "Epoch: 58\n",
      "training D Loss: 0.17009270448386668\n",
      "training G Loss: 5.334373910951614\n",
      "D_real_dis_acc: 60.6144\n",
      "D_fake_dis_acc: 60.2832\n",
      "D_real_aux_loss: 0.9644935272485018\n",
      "D_fake_aux_loss: 1.1858241845030337\n",
      "Epoch: 59\n",
      "training D Loss: 0.15588304228782654\n",
      "training G Loss: 5.443627433276176\n",
      "D_real_dis_acc: 60.912\n",
      "D_fake_dis_acc: 60.656\n",
      "D_real_aux_loss: 0.9791896605134011\n",
      "D_fake_aux_loss: 1.3727045221731067\n",
      "Epoch: 60\n",
      "training D Loss: 0.18406120340824128\n",
      "training G Loss: 5.546548962020874\n",
      "D_real_dis_acc: 60.3952\n",
      "D_fake_dis_acc: 60.1088\n",
      "D_real_aux_loss: 1.1212648571074009\n",
      "D_fake_aux_loss: 1.2190426658983808\n",
      "Epoch: 61\n",
      "training D Loss: 0.13683018180131912\n",
      "training G Loss: 5.438740633058548\n",
      "D_real_dis_acc: 61.304\n",
      "D_fake_dis_acc: 61.0688\n",
      "D_real_aux_loss: 0.9521628205537797\n",
      "D_fake_aux_loss: 1.1691490048941224\n",
      "Epoch: 62\n",
      "training D Loss: 0.1409117149591446\n",
      "training G Loss: 5.657980143165588\n",
      "D_real_dis_acc: 61.2576\n",
      "D_fake_dis_acc: 60.9104\n",
      "D_real_aux_loss: 1.02067100289464\n",
      "D_fake_aux_loss: 1.4520627568002558\n",
      "Epoch: 63\n",
      "training D Loss: 0.17061981611549853\n",
      "training G Loss: 5.585425629615783\n",
      "D_real_dis_acc: 60.6656\n",
      "D_fake_dis_acc: 60.2672\n",
      "D_real_aux_loss: 1.0671983430936933\n",
      "D_fake_aux_loss: 1.3001851652516052\n",
      "Epoch: 64\n",
      "training D Loss: 0.13568754372894765\n",
      "training G Loss: 5.625371369934082\n",
      "D_real_dis_acc: 61.3376\n",
      "D_fake_dis_acc: 61.1488\n",
      "D_real_aux_loss: 0.9272164053142071\n",
      "D_fake_aux_loss: 1.2666408213536255\n",
      "Epoch: 65\n",
      "training D Loss: 0.15604772200882436\n",
      "training G Loss: 5.632547057819367\n",
      "D_real_dis_acc: 60.9568\n",
      "D_fake_dis_acc: 60.704\n",
      "D_real_aux_loss: 0.9723388374820352\n",
      "D_fake_aux_loss: 1.3288311700189486\n",
      "Epoch: 66\n",
      "training D Loss: 0.14952147083729506\n",
      "training G Loss: 5.658568661594391\n",
      "D_real_dis_acc: 61.1376\n",
      "D_fake_dis_acc: 60.9232\n",
      "D_real_aux_loss: 1.009810532528162\n",
      "D_fake_aux_loss: 1.229133837230364\n",
      "Epoch: 67\n",
      "training D Loss: 0.17272541467398406\n",
      "training G Loss: 5.726681278133392\n",
      "D_real_dis_acc: 60.6\n",
      "D_fake_dis_acc: 60.32\n",
      "D_real_aux_loss: 1.0153118364408613\n",
      "D_fake_aux_loss: 1.347277599843964\n",
      "Epoch: 68\n",
      "training D Loss: 0.12270209342688322\n",
      "training G Loss: 5.703338774490357\n",
      "D_real_dis_acc: 61.744\n",
      "D_fake_dis_acc: 61.552\n",
      "D_real_aux_loss: 0.8823709052652121\n",
      "D_fake_aux_loss: 1.2555515498534777\n",
      "Epoch: 69\n",
      "training D Loss: 0.13560263583213092\n",
      "training G Loss: 5.866473022651673\n",
      "D_real_dis_acc: 61.376\n",
      "D_fake_dis_acc: 61.0416\n",
      "D_real_aux_loss: 0.9434342564806342\n",
      "D_fake_aux_loss: 1.2802788093807176\n",
      "Epoch: 70\n",
      "training D Loss: 0.17610425598621368\n",
      "training G Loss: 5.69901930360794\n",
      "D_real_dis_acc: 60.7456\n",
      "D_fake_dis_acc: 60.4\n",
      "D_real_aux_loss: 1.020441757029295\n",
      "D_fake_aux_loss: 1.452685448156111\n",
      "Epoch: 71\n",
      "training D Loss: 0.1343627085119486\n",
      "training G Loss: 5.788893166065216\n",
      "D_real_dis_acc: 61.3984\n",
      "D_fake_dis_acc: 61.0848\n",
      "D_real_aux_loss: 0.8586291698366404\n",
      "D_fake_aux_loss: 1.1213945380581543\n",
      "Epoch: 72\n",
      "training D Loss: 0.15341198041141033\n",
      "training G Loss: 5.853987144184113\n",
      "D_real_dis_acc: 61.168\n",
      "D_fake_dis_acc: 60.912\n",
      "D_real_aux_loss: 0.974074060934782\n",
      "D_fake_aux_loss: 1.281726773781702\n",
      "Epoch: 73\n",
      "training D Loss: 0.1293859467625618\n",
      "training G Loss: 5.815830390167236\n",
      "D_real_dis_acc: 61.6208\n",
      "D_fake_dis_acc: 61.416\n",
      "D_real_aux_loss: 1.0698817815303803\n",
      "D_fake_aux_loss: 1.478149925149232\n",
      "Epoch: 74\n",
      "training D Loss: 0.13633886014819147\n",
      "training G Loss: 5.950315780353546\n",
      "D_real_dis_acc: 61.4144\n",
      "D_fake_dis_acc: 61.1504\n",
      "D_real_aux_loss: 0.8914691013529896\n",
      "D_fake_aux_loss: 1.163555875292979\n",
      "Epoch: 75\n",
      "training D Loss: 0.11868432349637151\n",
      "training G Loss: 5.95127038064003\n",
      "D_real_dis_acc: 61.8304\n",
      "D_fake_dis_acc: 61.528\n",
      "D_real_aux_loss: 0.8146262200832367\n",
      "D_fake_aux_loss: 1.238074547558278\n",
      "Epoch: 76\n",
      "training D Loss: 0.15130937684476375\n",
      "training G Loss: 6.009391414928436\n",
      "D_real_dis_acc: 61.0224\n",
      "D_fake_dis_acc: 60.7888\n",
      "D_real_aux_loss: 0.8878641079455614\n",
      "D_fake_aux_loss: 1.4318729856789112\n",
      "Epoch: 77\n",
      "training D Loss: 0.12980144618302583\n",
      "training G Loss: 6.079854055404663\n",
      "D_real_dis_acc: 61.4384\n",
      "D_fake_dis_acc: 61.1152\n",
      "D_real_aux_loss: 0.806446670126915\n",
      "D_fake_aux_loss: 1.099819078160543\n",
      "Epoch: 78\n",
      "training D Loss: 0.13265585316866635\n",
      "training G Loss: 5.966188677501679\n",
      "D_real_dis_acc: 61.5456\n",
      "D_fake_dis_acc: 61.3296\n",
      "D_real_aux_loss: 0.898561596673727\n",
      "D_fake_aux_loss: 1.1504395800786094\n",
      "Epoch: 79\n",
      "training D Loss: 0.14115341375917195\n",
      "training G Loss: 6.1504030565261845\n",
      "D_real_dis_acc: 61.2608\n",
      "D_fake_dis_acc: 60.968\n",
      "D_real_aux_loss: 0.881902456855774\n",
      "D_fake_aux_loss: 1.4010152233186177\n",
      "Epoch: 80\n",
      "training D Loss: 0.11617822705954313\n",
      "training G Loss: 6.126413161373138\n",
      "D_real_dis_acc: 61.792\n",
      "D_fake_dis_acc: 61.5696\n",
      "D_real_aux_loss: 0.8436227130830288\n",
      "D_fake_aux_loss: 1.144883525658492\n",
      "Epoch: 81\n",
      "training D Loss: 0.12796650718525052\n",
      "training G Loss: 6.171114709186554\n",
      "D_real_dis_acc: 61.8208\n",
      "D_fake_dis_acc: 61.5136\n",
      "D_real_aux_loss: 0.9409215512633323\n",
      "D_fake_aux_loss: 1.409091034251079\n",
      "Epoch: 82\n",
      "training D Loss: 0.13411882320195437\n",
      "training G Loss: 6.331455881500244\n",
      "D_real_dis_acc: 61.24\n",
      "D_fake_dis_acc: 61.0608\n",
      "D_real_aux_loss: 0.834242108720541\n",
      "D_fake_aux_loss: 1.248085039447341\n",
      "Epoch: 83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training D Loss: 0.14189015330523252\n",
      "training G Loss: 6.258035359287262\n",
      "D_real_dis_acc: 61.3712\n",
      "D_fake_dis_acc: 61.1456\n",
      "D_real_aux_loss: 0.9186446513146163\n",
      "D_fake_aux_loss: 1.1990005317328498\n",
      "Epoch: 84\n",
      "training D Loss: 0.1286069469563663\n",
      "training G Loss: 6.293020923137664\n",
      "D_real_dis_acc: 61.696\n",
      "D_fake_dis_acc: 61.4\n",
      "D_real_aux_loss: 0.9256240832686424\n",
      "D_fake_aux_loss: 1.2994342371090315\n",
      "Epoch: 85\n",
      "training D Loss: 0.13120153655856848\n",
      "training G Loss: 6.1836177277565\n",
      "D_real_dis_acc: 61.528\n",
      "D_fake_dis_acc: 61.2848\n",
      "D_real_aux_loss: 0.8161172852903604\n",
      "D_fake_aux_loss: 1.1697780073984525\n",
      "Epoch: 86\n",
      "training D Loss: 0.13472361371219158\n",
      "training G Loss: 6.184031037759781\n",
      "D_real_dis_acc: 61.4656\n",
      "D_fake_dis_acc: 61.2752\n",
      "D_real_aux_loss: 0.7854646176189184\n",
      "D_fake_aux_loss: 1.3329733927787282\n",
      "Epoch: 87\n",
      "training D Loss: 0.12254385867863893\n",
      "training G Loss: 6.294933813476563\n",
      "D_real_dis_acc: 61.7424\n",
      "D_fake_dis_acc: 61.5008\n",
      "D_real_aux_loss: 0.8164220487624407\n",
      "D_fake_aux_loss: 1.2575173270476983\n",
      "Epoch: 88\n",
      "training D Loss: 0.11992354439646005\n",
      "training G Loss: 6.383164579105377\n",
      "D_real_dis_acc: 61.9056\n",
      "D_fake_dis_acc: 61.7216\n",
      "D_real_aux_loss: 0.8662164559960366\n",
      "D_fake_aux_loss: 1.2172095034936443\n",
      "Epoch: 89\n",
      "training D Loss: 0.11343540527671575\n",
      "training G Loss: 6.234798374080658\n",
      "D_real_dis_acc: 62.0224\n",
      "D_fake_dis_acc: 61.7712\n",
      "D_real_aux_loss: 0.922399765753746\n",
      "D_fake_aux_loss: 1.2255818393003195\n",
      "Epoch: 90\n",
      "training D Loss: 0.1195346387654543\n",
      "training G Loss: 6.43655661907196\n",
      "D_real_dis_acc: 61.6656\n",
      "D_fake_dis_acc: 61.4432\n",
      "D_real_aux_loss: 0.8616419417977333\n",
      "D_fake_aux_loss: 0.9970211637573316\n",
      "Epoch: 91\n",
      "training D Loss: 0.13340985937416552\n",
      "training G Loss: 6.13945475306511\n",
      "D_real_dis_acc: 61.7744\n",
      "D_fake_dis_acc: 61.5072\n",
      "D_real_aux_loss: 0.789657963180542\n",
      "D_fake_aux_loss: 1.1720280848714524\n",
      "Epoch: 92\n",
      "training D Loss: 0.13232975443303585\n",
      "training G Loss: 6.580721650028229\n",
      "D_real_dis_acc: 61.576\n",
      "D_fake_dis_acc: 61.3056\n",
      "D_real_aux_loss: 0.7753308705419302\n",
      "D_fake_aux_loss: 1.1132906241709832\n",
      "Epoch: 93\n",
      "training D Loss: 0.11789591905325651\n",
      "training G Loss: 6.444261071825028\n",
      "D_real_dis_acc: 61.9344\n",
      "D_fake_dis_acc: 61.6576\n",
      "D_real_aux_loss: 0.8914473563797772\n",
      "D_fake_aux_loss: 1.2069989954207092\n",
      "Epoch: 94\n",
      "training D Loss: 0.11803857949525118\n",
      "training G Loss: 6.274501262283326\n",
      "D_real_dis_acc: 61.8448\n",
      "D_fake_dis_acc: 61.6816\n",
      "D_real_aux_loss: 0.843788628077507\n",
      "D_fake_aux_loss: 1.2874728294884785\n",
      "Epoch: 95\n",
      "training D Loss: 0.11660711576491595\n",
      "training G Loss: 6.445051720237732\n",
      "D_real_dis_acc: 61.9408\n",
      "D_fake_dis_acc: 61.6512\n",
      "D_real_aux_loss: 0.8528417770594359\n",
      "D_fake_aux_loss: 1.1728873820301144\n",
      "Epoch: 96\n",
      "training D Loss: 0.10112920214235782\n",
      "training G Loss: 6.653495853376389\n",
      "D_real_dis_acc: 62.1616\n",
      "D_fake_dis_acc: 61.928\n",
      "D_real_aux_loss: 0.7856419660612941\n",
      "D_fake_aux_loss: 1.1730949017720298\n",
      "Epoch: 97\n",
      "training D Loss: 0.1328221799686551\n",
      "training G Loss: 6.6900978079319\n",
      "D_real_dis_acc: 61.6832\n",
      "D_fake_dis_acc: 61.448\n",
      "D_real_aux_loss: 0.8110506111741066\n",
      "D_fake_aux_loss: 1.1217418807171284\n",
      "Epoch: 98\n",
      "training D Loss: 0.11331153012812138\n",
      "training G Loss: 6.496078995609284\n",
      "D_real_dis_acc: 61.8656\n",
      "D_fake_dis_acc: 61.704\n",
      "D_real_aux_loss: 0.7783078674048185\n",
      "D_fake_aux_loss: 1.126327451720275\n",
      "Epoch: 99\n",
      "training D Loss: 0.1166827036857605\n",
      "training G Loss: 6.595466397476196\n",
      "D_real_dis_acc: 61.8368\n",
      "D_fake_dis_acc: 61.6272\n",
      "D_real_aux_loss: 0.8202941893465817\n",
      "D_fake_aux_loss: 1.3627915362355298\n",
      "Epoch: 100\n",
      "training D Loss: 0.11361242136210203\n",
      "training G Loss: 6.586520883560181\n",
      "D_real_dis_acc: 62.0688\n",
      "D_fake_dis_acc: 61.8064\n",
      "D_real_aux_loss: 0.7587455033555627\n",
      "D_fake_aux_loss: 1.123488587581506\n",
      "Epoch: 101\n",
      "training D Loss: 0.11525249181389809\n",
      "training G Loss: 6.6114086986541745\n",
      "D_real_dis_acc: 61.9568\n",
      "D_fake_dis_acc: 61.8112\n",
      "D_real_aux_loss: 0.8653752988308668\n",
      "D_fake_aux_loss: 1.3247830905046314\n",
      "Epoch: 102\n",
      "training D Loss: 0.12541324512660504\n",
      "training G Loss: 6.6340516804218295\n",
      "D_real_dis_acc: 61.744\n",
      "D_fake_dis_acc: 61.5312\n",
      "D_real_aux_loss: 0.7997937705308199\n",
      "D_fake_aux_loss: 1.2423669446764514\n",
      "Epoch: 103\n",
      "training D Loss: 0.10774391142874956\n",
      "training G Loss: 6.60898176419735\n",
      "D_real_dis_acc: 62.0256\n",
      "D_fake_dis_acc: 61.904\n",
      "D_real_aux_loss: 0.7855383213624358\n",
      "D_fake_aux_loss: 1.2449139276186005\n",
      "Epoch: 104\n",
      "training D Loss: 0.11261778643131257\n",
      "training G Loss: 6.6397368914604185\n",
      "D_real_dis_acc: 61.96\n",
      "D_fake_dis_acc: 61.8576\n",
      "D_real_aux_loss: 0.824101170104742\n",
      "D_fake_aux_loss: 1.2276039941932075\n",
      "Epoch: 105\n",
      "training D Loss: 0.1262722529679537\n",
      "training G Loss: 6.4422268854498865\n",
      "D_real_dis_acc: 61.9152\n",
      "D_fake_dis_acc: 61.7616\n",
      "D_real_aux_loss: 0.8242795072034002\n",
      "D_fake_aux_loss: 1.200742791353818\n",
      "Epoch: 106\n",
      "training D Loss: 0.0969380191422999\n",
      "training G Loss: 6.851631749343872\n",
      "D_real_dis_acc: 62.3776\n",
      "D_fake_dis_acc: 62.1376\n",
      "D_real_aux_loss: 0.7684591746032238\n",
      "D_fake_aux_loss: 1.17288563412223\n",
      "Epoch: 107\n",
      "training D Loss: 0.12133902878388762\n",
      "training G Loss: 6.79070322523117\n",
      "D_real_dis_acc: 61.7232\n",
      "D_fake_dis_acc: 61.4832\n",
      "D_real_aux_loss: 0.8563311451347545\n",
      "D_fake_aux_loss: 1.2970809203577227\n",
      "Epoch: 108\n",
      "training D Loss: 0.10714355755373836\n",
      "training G Loss: 6.733381148052215\n",
      "D_real_dis_acc: 62.0736\n",
      "D_fake_dis_acc: 61.9424\n",
      "D_real_aux_loss: 0.7009183594256639\n",
      "D_fake_aux_loss: 1.0022064931662753\n",
      "Epoch: 109\n",
      "training D Loss: 0.13719990327060222\n",
      "training G Loss: 6.741495793366433\n",
      "D_real_dis_acc: 61.6896\n",
      "D_fake_dis_acc: 61.4864\n",
      "D_real_aux_loss: 0.9046995004758239\n",
      "D_fake_aux_loss: 1.5031478266138583\n",
      "Epoch: 110\n",
      "training D Loss: 0.08019115293174982\n",
      "training G Loss: 6.793982284259796\n",
      "D_real_dis_acc: 62.6832\n",
      "D_fake_dis_acc: 62.4784\n",
      "D_real_aux_loss: 0.6583586419314146\n",
      "D_fake_aux_loss: 1.1613600335502066\n",
      "Epoch: 111\n",
      "training D Loss: 0.10771691957563162\n",
      "training G Loss: 6.8254334714412686\n",
      "D_real_dis_acc: 62.2208\n",
      "D_fake_dis_acc: 62.0704\n",
      "D_real_aux_loss: 0.7849130157470703\n",
      "D_fake_aux_loss: 1.2903064353679308\n",
      "Epoch: 112\n",
      "training D Loss: 0.09010829043239355\n",
      "training G Loss: 6.950919131660461\n",
      "D_real_dis_acc: 62.4896\n",
      "D_fake_dis_acc: 62.296\n",
      "D_real_aux_loss: 0.7235300084471703\n",
      "D_fake_aux_loss: 1.0441654388447759\n",
      "Epoch: 113\n",
      "training D Loss: 0.12294803583696484\n",
      "training G Loss: 7.0254609586715695\n",
      "D_real_dis_acc: 61.8816\n",
      "D_fake_dis_acc: 61.752\n",
      "D_real_aux_loss: 0.7929020694464445\n",
      "D_fake_aux_loss: 1.0602726116373205\n",
      "Epoch: 114\n",
      "training D Loss: 0.08637779532372951\n",
      "training G Loss: 6.932751849079132\n",
      "D_real_dis_acc: 62.4656\n",
      "D_fake_dis_acc: 62.2624\n",
      "D_real_aux_loss: 0.7021829629793763\n",
      "D_fake_aux_loss: 1.042023398545198\n",
      "Epoch: 115\n",
      "training D Loss: 0.14857992255166172\n",
      "training G Loss: 7.153576780629158\n",
      "D_real_dis_acc: 61.6816\n",
      "D_fake_dis_acc: 61.4624\n",
      "D_real_aux_loss: 0.7207009383112192\n",
      "D_fake_aux_loss: 1.1144244022801983\n",
      "Epoch: 116\n",
      "training D Loss: 0.09544263948872686\n",
      "training G Loss: 6.617565925598145\n",
      "D_real_dis_acc: 62.2752\n",
      "D_fake_dis_acc: 62.0496\n",
      "D_real_aux_loss: 0.6384301466494798\n",
      "D_fake_aux_loss: 1.0817455665907356\n",
      "Epoch: 117\n",
      "training D Loss: 0.091442562866956\n",
      "training G Loss: 6.894873101234436\n",
      "D_real_dis_acc: 62.3392\n",
      "D_fake_dis_acc: 62.2384\n",
      "D_real_aux_loss: 0.5731890080869197\n",
      "D_fake_aux_loss: 0.9888060582038015\n",
      "Epoch: 118\n",
      "training D Loss: 0.11800681428909301\n",
      "training G Loss: 6.88943148150444\n",
      "D_real_dis_acc: 61.9776\n",
      "D_fake_dis_acc: 61.8528\n",
      "D_real_aux_loss: 0.6615061606094241\n",
      "D_fake_aux_loss: 1.0232721940177028\n",
      "Epoch: 119\n",
      "training D Loss: 0.09179773825407028\n",
      "training G Loss: 6.909992940092087\n",
      "D_real_dis_acc: 62.4976\n",
      "D_fake_dis_acc: 62.296\n",
      "D_real_aux_loss: 0.6598874574080109\n",
      "D_fake_aux_loss: 0.9966750118321739\n",
      "Epoch: 120\n",
      "training D Loss: 0.09077592602446675\n",
      "training G Loss: 7.122285514545441\n",
      "D_real_dis_acc: 62.5216\n",
      "D_fake_dis_acc: 62.344\n",
      "D_real_aux_loss: 0.7023859349817038\n",
      "D_fake_aux_loss: 1.0941568054888398\n",
      "Epoch: 121\n",
      "training D Loss: 0.10687627538144588\n",
      "training G Loss: 7.061394179916382\n",
      "D_real_dis_acc: 62.1456\n",
      "D_fake_dis_acc: 62.0384\n",
      "D_real_aux_loss: 0.7307447417348624\n",
      "D_fake_aux_loss: 1.216407141908072\n",
      "Epoch: 122\n",
      "training D Loss: 0.10592674749195576\n",
      "training G Loss: 6.950214320659637\n",
      "D_real_dis_acc: 62.128\n",
      "D_fake_dis_acc: 62.0\n",
      "D_real_aux_loss: 0.7135007247209549\n",
      "D_fake_aux_loss: 1.0047506208724342\n",
      "Epoch: 123\n",
      "training D Loss: 0.09575022428147495\n",
      "training G Loss: 7.0105284399032595\n",
      "D_real_dis_acc: 62.4208\n",
      "D_fake_dis_acc: 62.3136\n",
      "D_real_aux_loss: 0.778232578650117\n",
      "D_fake_aux_loss: 1.283927402572194\n",
      "Epoch: 124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training D Loss: 0.09589251101911068\n",
      "training G Loss: 7.0783509604454045\n",
      "D_real_dis_acc: 62.3776\n",
      "D_fake_dis_acc: 62.2448\n",
      "D_real_aux_loss: 0.7109400512427092\n",
      "D_fake_aux_loss: 1.3908422490950674\n",
      "Epoch: 125\n",
      "training D Loss: 0.11469513545408845\n",
      "training G Loss: 7.223625423622131\n",
      "D_real_dis_acc: 61.9168\n",
      "D_fake_dis_acc: 61.688\n",
      "D_real_aux_loss: 0.7104076077222824\n",
      "D_fake_aux_loss: 0.9689459162730258\n",
      "Epoch: 126\n",
      "training D Loss: 0.09770737611949444\n",
      "training G Loss: 7.1615738733291625\n",
      "D_real_dis_acc: 62.1776\n",
      "D_fake_dis_acc: 62.0432\n",
      "D_real_aux_loss: 0.6783396767899394\n",
      "D_fake_aux_loss: 0.9724351798757911\n",
      "Epoch: 127\n",
      "training D Loss: 0.08387158966735006\n",
      "training G Loss: 7.132795063972473\n",
      "D_real_dis_acc: 62.5088\n",
      "D_fake_dis_acc: 62.408\n",
      "D_real_aux_loss: 0.6319580152601003\n",
      "D_fake_aux_loss: 1.016373097742442\n",
      "Epoch: 128\n",
      "training D Loss: 0.09061391914263367\n",
      "training G Loss: 7.242408863067627\n",
      "D_real_dis_acc: 62.4864\n",
      "D_fake_dis_acc: 62.3568\n",
      "D_real_aux_loss: 0.6678793776020407\n",
      "D_fake_aux_loss: 1.291724503125716\n",
      "Epoch: 129\n",
      "training D Loss: 0.1370578596070409\n",
      "training G Loss: 7.183160860973596\n",
      "D_real_dis_acc: 61.8576\n",
      "D_fake_dis_acc: 61.6528\n",
      "D_real_aux_loss: 0.7292428475946188\n",
      "D_fake_aux_loss: 1.2183522731063887\n",
      "Epoch: 130\n",
      "training D Loss: 0.08132122229114175\n",
      "training G Loss: 7.132739082527161\n",
      "D_real_dis_acc: 62.5808\n",
      "D_fake_dis_acc: 62.456\n",
      "D_real_aux_loss: 0.6078470631815494\n",
      "D_fake_aux_loss: 1.028877372645843\n",
      "Epoch: 131\n",
      "training D Loss: 0.09479081499502062\n",
      "training G Loss: 7.373553741741181\n",
      "D_real_dis_acc: 62.3008\n",
      "D_fake_dis_acc: 62.12\n",
      "D_real_aux_loss: 0.7391590228669346\n",
      "D_fake_aux_loss: 1.1717526747197844\n",
      "Epoch: 132\n",
      "training D Loss: 0.11889929809942841\n",
      "training G Loss: 7.147015247154235\n",
      "D_real_dis_acc: 62.0848\n",
      "D_fake_dis_acc: 61.9824\n",
      "D_real_aux_loss: 0.756130671274662\n",
      "D_fake_aux_loss: 1.1510152239184828\n",
      "Epoch: 133\n",
      "training D Loss: 0.06733631527349353\n",
      "training G Loss: 7.139538772964477\n",
      "D_real_dis_acc: 62.8976\n",
      "D_fake_dis_acc: 62.8176\n",
      "D_real_aux_loss: 0.635811775135994\n",
      "D_fake_aux_loss: 1.0932415223026881\n",
      "Epoch: 134\n",
      "training D Loss: 0.09020806419923902\n",
      "training G Loss: 7.3918244707107545\n",
      "D_real_dis_acc: 62.3296\n",
      "D_fake_dis_acc: 62.2304\n",
      "D_real_aux_loss: 0.6315966665402055\n",
      "D_fake_aux_loss: 1.0373855862193275\n",
      "Epoch: 135\n",
      "training D Loss: 0.10946220328882336\n",
      "training G Loss: 7.28389078130722\n",
      "D_real_dis_acc: 62.1056\n",
      "D_fake_dis_acc: 61.968\n",
      "D_real_aux_loss: 0.7024653593577445\n",
      "D_fake_aux_loss: 1.0897506857570027\n",
      "Epoch: 136\n",
      "training D Loss: 0.07617427843436599\n",
      "training G Loss: 7.386381861305237\n",
      "D_real_dis_acc: 62.7184\n",
      "D_fake_dis_acc: 62.512\n",
      "D_real_aux_loss: 0.6306307196199894\n",
      "D_fake_aux_loss: 1.0906981219683307\n",
      "Epoch: 137\n",
      "training D Loss: 0.10911382831037045\n",
      "training G Loss: 7.349673023962975\n",
      "D_real_dis_acc: 62.128\n",
      "D_fake_dis_acc: 61.9536\n",
      "D_real_aux_loss: 0.6929627073556185\n",
      "D_fake_aux_loss: 0.9920666536443867\n",
      "Epoch: 138\n",
      "training D Loss: 0.08027873485162854\n",
      "training G Loss: 7.48409740819931\n",
      "D_real_dis_acc: 62.6144\n",
      "D_fake_dis_acc: 62.5104\n",
      "D_real_aux_loss: 0.5985134407952428\n",
      "D_fake_aux_loss: 1.1841554297897032\n",
      "Epoch: 139\n",
      "training D Loss: 0.08209778577908873\n",
      "training G Loss: 7.579940937042236\n",
      "D_real_dis_acc: 62.6368\n",
      "D_fake_dis_acc: 62.4352\n",
      "D_real_aux_loss: 0.6452105055809021\n",
      "D_fake_aux_loss: 1.1224781405241229\n",
      "Epoch: 140\n",
      "training D Loss: 0.14189911519289017\n",
      "training G Loss: 7.438713104391098\n",
      "D_real_dis_acc: 61.8336\n",
      "D_fake_dis_acc: 61.6864\n",
      "D_real_aux_loss: 0.8243795395806431\n",
      "D_fake_aux_loss: 1.2169023498332594\n",
      "Epoch: 141\n",
      "training D Loss: 0.07621008087694645\n",
      "training G Loss: 7.382549870109558\n",
      "D_real_dis_acc: 62.7168\n",
      "D_fake_dis_acc: 62.6416\n",
      "D_real_aux_loss: 0.629239163595438\n",
      "D_fake_aux_loss: 1.3001919621183071\n",
      "Epoch: 142\n",
      "training D Loss: 0.09048611815422773\n",
      "training G Loss: 7.5540750380516055\n",
      "D_real_dis_acc: 62.4512\n",
      "D_fake_dis_acc: 62.2864\n",
      "D_real_aux_loss: 0.6174495437622071\n",
      "D_fake_aux_loss: 1.1856707933730446\n",
      "Epoch: 143\n",
      "training D Loss: 0.0974719607539475\n",
      "training G Loss: 7.470785630607605\n",
      "D_real_dis_acc: 62.4416\n",
      "D_fake_dis_acc: 62.2592\n",
      "D_real_aux_loss: 0.637978432610631\n",
      "D_fake_aux_loss: 1.3051858086853287\n",
      "Epoch: 144\n",
      "training D Loss: 0.08853561010882259\n",
      "training G Loss: 7.51025820980072\n",
      "D_real_dis_acc: 62.4784\n",
      "D_fake_dis_acc: 62.3408\n",
      "D_real_aux_loss: 0.6331807845324278\n",
      "D_fake_aux_loss: 1.4166920459615067\n",
      "Epoch: 145\n",
      "training D Loss: 0.09719273006170988\n",
      "training G Loss: 7.565281119155884\n",
      "D_real_dis_acc: 62.136\n",
      "D_fake_dis_acc: 62.0608\n",
      "D_real_aux_loss: 0.6285576578125358\n",
      "D_fake_aux_loss: 1.3007511508309049\n",
      "Epoch: 146\n",
      "training D Loss: 0.07758379089348018\n",
      "training G Loss: 7.612851954841614\n",
      "D_real_dis_acc: 62.7008\n",
      "D_fake_dis_acc: 62.5648\n",
      "D_real_aux_loss: 0.6319934550851584\n",
      "D_fake_aux_loss: 1.2366454505541362\n",
      "Epoch: 147\n",
      "training D Loss: 0.12863355986848474\n",
      "training G Loss: 7.500673710978031\n",
      "D_real_dis_acc: 61.8224\n",
      "D_fake_dis_acc: 61.6896\n",
      "D_real_aux_loss: 0.7792254625231028\n",
      "D_fake_aux_loss: 1.3116762325358577\n",
      "Epoch: 148\n",
      "training D Loss: 0.09481058780103922\n",
      "training G Loss: 7.5160630460739135\n",
      "D_real_dis_acc: 62.3968\n",
      "D_fake_dis_acc: 62.3008\n",
      "D_real_aux_loss: 0.5424613280668855\n",
      "D_fake_aux_loss: 1.5060984825489112\n",
      "Epoch: 149\n",
      "training D Loss: 0.0805940878547728\n",
      "training G Loss: 7.464602392959595\n",
      "D_real_dis_acc: 62.6224\n",
      "D_fake_dis_acc: 62.4176\n",
      "D_real_aux_loss: 0.604822960370779\n",
      "D_fake_aux_loss: 1.343692371335253\n",
      "Epoch: 150\n",
      "training D Loss: 0.11867450673021376\n",
      "training G Loss: 7.407064615797997\n",
      "D_real_dis_acc: 62.0192\n",
      "D_fake_dis_acc: 61.8304\n",
      "D_real_aux_loss: 0.6399768630728125\n",
      "D_fake_aux_loss: 1.1136663886166178\n",
      "Epoch: 151\n",
      "training D Loss: 0.10296034004613758\n",
      "training G Loss: 7.532765438270569\n",
      "D_real_dis_acc: 62.3808\n",
      "D_fake_dis_acc: 62.2448\n",
      "D_real_aux_loss: 0.6986089281439781\n",
      "D_fake_aux_loss: 2.270531724109687\n",
      "Epoch: 152\n",
      "training D Loss: 0.09054133943393826\n",
      "training G Loss: 7.340033513736725\n",
      "D_real_dis_acc: 62.552\n",
      "D_fake_dis_acc: 62.3632\n",
      "D_real_aux_loss: 0.6885044752784073\n",
      "D_fake_aux_loss: 1.24840934276646\n",
      "Epoch: 153\n",
      "training D Loss: 0.09294435041323304\n",
      "training G Loss: 7.577899073791504\n",
      "D_real_dis_acc: 62.3696\n",
      "D_fake_dis_acc: 62.2336\n",
      "D_real_aux_loss: 0.6920160867035389\n",
      "D_fake_aux_loss: 1.4869902654526754\n",
      "Epoch: 154\n",
      "training D Loss: 0.08959777418784798\n",
      "training G Loss: 7.479132588338852\n",
      "D_real_dis_acc: 62.424\n",
      "D_fake_dis_acc: 62.3632\n",
      "D_real_aux_loss: 0.6743996331557631\n",
      "D_fake_aux_loss: 1.1632984609579669\n",
      "Epoch: 155\n",
      "training D Loss: 0.09408743915222585\n",
      "training G Loss: 7.699710841083527\n",
      "D_real_dis_acc: 62.3216\n",
      "D_fake_dis_acc: 62.2352\n",
      "D_real_aux_loss: 0.6210022043704987\n",
      "D_fake_aux_loss: 1.4760651800843887\n",
      "Epoch: 156\n",
      "training D Loss: 0.12912516693100334\n",
      "training G Loss: 7.676112445569038\n",
      "D_real_dis_acc: 61.8112\n",
      "D_fake_dis_acc: 61.6672\n",
      "D_real_aux_loss: 0.7195658530816436\n",
      "D_fake_aux_loss: 1.1748185173837002\n",
      "Epoch: 157\n",
      "training D Loss: 0.08876204476431013\n",
      "training G Loss: 7.302850435829162\n",
      "D_real_dis_acc: 62.3712\n",
      "D_fake_dis_acc: 62.248\n",
      "D_real_aux_loss: 0.6215124784320593\n",
      "D_fake_aux_loss: 1.1757372653723694\n",
      "Epoch: 158\n",
      "training D Loss: 0.09177658472880722\n",
      "training G Loss: 7.589809464645386\n",
      "D_real_dis_acc: 62.4496\n",
      "D_fake_dis_acc: 62.2752\n",
      "D_real_aux_loss: 0.6099877145946025\n",
      "D_fake_aux_loss: 1.6333493095266634\n",
      "Epoch: 159\n",
      "training D Loss: 0.10793943843469024\n",
      "training G Loss: 7.563269472980499\n",
      "D_real_dis_acc: 62.2464\n",
      "D_fake_dis_acc: 62.1104\n",
      "D_real_aux_loss: 0.6629126457929612\n",
      "D_fake_aux_loss: 1.8095825186787173\n",
      "Epoch: 160\n",
      "training D Loss: 0.08884904773160815\n",
      "training G Loss: 7.565561325454712\n",
      "D_real_dis_acc: 62.3408\n",
      "D_fake_dis_acc: 62.2864\n",
      "D_real_aux_loss: 0.585312903650105\n",
      "D_fake_aux_loss: 1.2327578561986796\n",
      "Epoch: 161\n",
      "training D Loss: 0.1165189805150032\n",
      "training G Loss: 7.434729607582092\n",
      "D_real_dis_acc: 61.8272\n",
      "D_fake_dis_acc: 61.6704\n",
      "D_real_aux_loss: 0.6682418778449297\n",
      "D_fake_aux_loss: 1.1803360706506296\n",
      "Epoch: 162\n",
      "training D Loss: 0.09254073166809976\n",
      "training G Loss: 7.515833964920044\n",
      "D_real_dis_acc: 62.3872\n",
      "D_fake_dis_acc: 62.2608\n",
      "D_real_aux_loss: 0.5304646078720688\n",
      "D_fake_aux_loss: 1.2952028033106122\n",
      "Epoch: 163\n",
      "training D Loss: 0.1000429553978145\n",
      "training G Loss: 7.53648065404892\n",
      "D_real_dis_acc: 62.2736\n",
      "D_fake_dis_acc: 62.1376\n",
      "D_real_aux_loss: 0.6138412714734673\n",
      "D_fake_aux_loss: 1.504213039838709\n",
      "Epoch: 164\n",
      "training D Loss: 0.09656732144206762\n",
      "training G Loss: 7.44658222770691\n",
      "D_real_dis_acc: 62.3408\n",
      "D_fake_dis_acc: 62.1504\n",
      "D_real_aux_loss: 0.6634600084634498\n",
      "D_fake_aux_loss: 1.2461703993828153\n",
      "Epoch: 165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training D Loss: 0.09883706137686968\n",
      "training G Loss: 7.559238776779175\n",
      "D_real_dis_acc: 62.1552\n",
      "D_fake_dis_acc: 62.0496\n",
      "D_real_aux_loss: 0.57547197599262\n",
      "D_fake_aux_loss: 1.2344295302983372\n",
      "Epoch: 166\n",
      "training D Loss: 0.10891657056808472\n",
      "training G Loss: 7.549034243965149\n",
      "D_real_dis_acc: 62.0688\n",
      "D_fake_dis_acc: 61.92\n",
      "D_real_aux_loss: 0.6079664593085646\n",
      "D_fake_aux_loss: 1.4108734742912463\n",
      "Epoch: 167\n",
      "training D Loss: 0.08446296211108566\n",
      "training G Loss: 7.630634232330323\n",
      "D_real_dis_acc: 62.5504\n",
      "D_fake_dis_acc: 62.3408\n",
      "D_real_aux_loss: 0.598999728512764\n",
      "D_fake_aux_loss: 1.2482963443958202\n",
      "Epoch: 168\n",
      "training D Loss: 0.09348692250698805\n",
      "training G Loss: 7.614599384880066\n",
      "D_real_dis_acc: 62.408\n",
      "D_fake_dis_acc: 62.2432\n",
      "D_real_aux_loss: 0.6586786460161209\n",
      "D_fake_aux_loss: 1.5932017828548326\n",
      "Epoch: 169\n",
      "training D Loss: 0.11661626283153892\n",
      "training G Loss: 7.733311151409149\n",
      "D_real_dis_acc: 61.8864\n",
      "D_fake_dis_acc: 61.7072\n",
      "D_real_aux_loss: 0.6807973698824644\n",
      "D_fake_aux_loss: 1.2820731237642466\n",
      "Epoch: 170\n",
      "training D Loss: 0.09757174890786409\n",
      "training G Loss: 7.625630749320984\n",
      "D_real_dis_acc: 62.2864\n",
      "D_fake_dis_acc: 62.1328\n",
      "D_real_aux_loss: 0.629694053581357\n",
      "D_fake_aux_loss: 1.4250183421696536\n",
      "Epoch: 171\n",
      "training D Loss: 0.1025041875205934\n",
      "training G Loss: 7.547514861321449\n",
      "D_real_dis_acc: 62.2768\n",
      "D_fake_dis_acc: 62.1312\n",
      "D_real_aux_loss: 0.6659449617728591\n",
      "D_fake_aux_loss: 1.4745841796529013\n",
      "Epoch: 172\n",
      "training D Loss: 0.08753227669000625\n",
      "training G Loss: 7.4177660470962525\n",
      "D_real_dis_acc: 62.5056\n",
      "D_fake_dis_acc: 62.3504\n",
      "D_real_aux_loss: 0.5932208348095417\n",
      "D_fake_aux_loss: 1.170568799520284\n",
      "Epoch: 173\n",
      "training D Loss: 0.08525247988253831\n",
      "training G Loss: 7.619065871429443\n",
      "D_real_dis_acc: 62.472\n",
      "D_fake_dis_acc: 62.3088\n",
      "D_real_aux_loss: 0.6168593090578913\n",
      "D_fake_aux_loss: 1.3005788471415174\n",
      "Epoch: 174\n",
      "training D Loss: 0.09281125678941607\n",
      "training G Loss: 7.676395718336106\n",
      "D_real_dis_acc: 62.4816\n",
      "D_fake_dis_acc: 62.2896\n",
      "D_real_aux_loss: 0.6265781890206039\n",
      "D_fake_aux_loss: 1.4123224883852528\n",
      "Epoch: 175\n",
      "training D Loss: 0.08063192745223641\n",
      "training G Loss: 7.70577718296051\n",
      "D_real_dis_acc: 62.5744\n",
      "D_fake_dis_acc: 62.4048\n",
      "D_real_aux_loss: 0.6268147487998009\n",
      "D_fake_aux_loss: 1.2560889241384343\n",
      "Epoch: 176\n",
      "training D Loss: 0.0995229114934802\n",
      "training G Loss: 7.815237946748733\n",
      "D_real_dis_acc: 62.2304\n",
      "D_fake_dis_acc: 62.1376\n",
      "D_real_aux_loss: 0.659442523959279\n",
      "D_fake_aux_loss: 1.3286384519776329\n",
      "Epoch: 177\n",
      "training D Loss: 0.09091222596019506\n",
      "training G Loss: 7.698532572507858\n",
      "D_real_dis_acc: 62.3872\n",
      "D_fake_dis_acc: 62.2688\n",
      "D_real_aux_loss: 0.5879593730926513\n",
      "D_fake_aux_loss: 1.3231387324323878\n",
      "Epoch: 178\n",
      "training D Loss: 0.07709432030543685\n",
      "training G Loss: 7.882121790695191\n",
      "D_real_dis_acc: 62.7104\n",
      "D_fake_dis_acc: 62.5264\n",
      "D_real_aux_loss: 0.5481526228621602\n",
      "D_fake_aux_loss: 1.2014405590656214\n",
      "Epoch: 179\n",
      "training D Loss: 0.1190901319809258\n",
      "training G Loss: 7.616376542282104\n",
      "D_real_dis_acc: 61.8144\n",
      "D_fake_dis_acc: 61.7408\n",
      "D_real_aux_loss: 0.667567572043091\n",
      "D_fake_aux_loss: 1.298568302957248\n",
      "Epoch: 180\n",
      "training D Loss: 0.08669916762262583\n",
      "training G Loss: 7.981540027236939\n",
      "D_real_dis_acc: 62.4608\n",
      "D_fake_dis_acc: 62.3184\n",
      "D_real_aux_loss: 0.6214093585401773\n",
      "D_fake_aux_loss: 1.302879957669042\n",
      "Epoch: 181\n",
      "training D Loss: 0.11439179461598396\n",
      "training G Loss: 7.769209562397003\n",
      "D_real_dis_acc: 62.0816\n",
      "D_fake_dis_acc: 61.9296\n",
      "D_real_aux_loss: 0.6693258568182587\n",
      "D_fake_aux_loss: 1.415823688713368\n",
      "Epoch: 182\n",
      "training D Loss: 0.07235880524143577\n",
      "training G Loss: 7.759016204166413\n",
      "D_real_dis_acc: 62.7904\n",
      "D_fake_dis_acc: 62.6048\n",
      "D_real_aux_loss: 0.47795402648597957\n",
      "D_fake_aux_loss: 1.2123986448872834\n",
      "Epoch: 183\n",
      "training D Loss: 0.08807475455477834\n",
      "training G Loss: 7.824821777248382\n",
      "D_real_dis_acc: 62.4672\n",
      "D_fake_dis_acc: 62.296\n",
      "D_real_aux_loss: 0.6137143151640893\n",
      "D_fake_aux_loss: 1.4142302376260516\n",
      "Epoch: 184\n",
      "training D Loss: 0.10742791667431593\n",
      "training G Loss: 8.005140028381348\n",
      "D_real_dis_acc: 62.112\n",
      "D_fake_dis_acc: 61.9456\n",
      "D_real_aux_loss: 0.623190806081891\n",
      "D_fake_aux_loss: 1.816053404378239\n",
      "Epoch: 185\n",
      "training D Loss: 0.11411660585924983\n",
      "training G Loss: 7.665010131072998\n",
      "D_real_dis_acc: 62.1648\n",
      "D_fake_dis_acc: 62.0432\n",
      "D_real_aux_loss: 0.6507445079863071\n",
      "D_fake_aux_loss: 1.525399460618943\n",
      "Epoch: 186\n",
      "training D Loss: 0.08008698702082039\n",
      "training G Loss: 7.8586441573143\n",
      "D_real_dis_acc: 62.5808\n",
      "D_fake_dis_acc: 62.4032\n",
      "D_real_aux_loss: 0.5452041350647807\n",
      "D_fake_aux_loss: 1.0541425985964015\n",
      "Epoch: 187\n",
      "training D Loss: 0.08025540497228503\n",
      "training G Loss: 7.713109059405327\n",
      "D_real_dis_acc: 62.584\n",
      "D_fake_dis_acc: 62.4944\n",
      "D_real_aux_loss: 0.4984825928032398\n",
      "D_fake_aux_loss: 1.0081450271090493\n",
      "Epoch: 188\n",
      "training D Loss: 0.0892581908274442\n",
      "training G Loss: 7.865638202095032\n",
      "D_real_dis_acc: 62.5472\n",
      "D_fake_dis_acc: 62.3648\n",
      "D_real_aux_loss: 0.5340449020728469\n",
      "D_fake_aux_loss: 1.2751355949446093\n",
      "Epoch: 189\n",
      "training D Loss: 0.0812246170848608\n",
      "training G Loss: 7.987850832366943\n",
      "D_real_dis_acc: 62.544\n",
      "D_fake_dis_acc: 62.3216\n",
      "D_real_aux_loss: 0.5678665497019887\n",
      "D_fake_aux_loss: 1.2015295156830457\n",
      "Epoch: 190\n",
      "training D Loss: 0.12043955399617552\n",
      "training G Loss: 7.870815047645569\n",
      "D_real_dis_acc: 62.2496\n",
      "D_fake_dis_acc: 62.1312\n",
      "D_real_aux_loss: 0.6683764994949103\n",
      "D_fake_aux_loss: 1.4754545993323438\n",
      "Epoch: 191\n",
      "training D Loss: 0.07351785887926816\n",
      "training G Loss: 7.6719218334198\n",
      "D_real_dis_acc: 62.7584\n",
      "D_fake_dis_acc: 62.616\n",
      "D_real_aux_loss: 0.5553942309588193\n",
      "D_fake_aux_loss: 1.2550288509376346\n",
      "Epoch: 192\n",
      "training D Loss: 0.09506885742545128\n",
      "training G Loss: 7.821189642333985\n",
      "D_real_dis_acc: 62.2912\n",
      "D_fake_dis_acc: 62.1808\n",
      "D_real_aux_loss: 0.6137766641765833\n",
      "D_fake_aux_loss: 1.4162334327135235\n",
      "Epoch: 193\n",
      "training D Loss: 0.09874084582179785\n",
      "training G Loss: 7.894014168643952\n",
      "D_real_dis_acc: 62.2544\n",
      "D_fake_dis_acc: 62.1248\n",
      "D_real_aux_loss: 0.5793281972333789\n",
      "D_fake_aux_loss: 1.409434978473559\n",
      "Epoch: 194\n",
      "training D Loss: 0.08156986098140478\n",
      "training G Loss: 7.868085521888733\n",
      "D_real_dis_acc: 62.6272\n",
      "D_fake_dis_acc: 62.5024\n",
      "D_real_aux_loss: 0.5071377234250307\n",
      "D_fake_aux_loss: 1.5598718934577425\n",
      "Epoch: 195\n",
      "training D Loss: 0.10500395762547851\n",
      "training G Loss: 7.974244732093811\n",
      "D_real_dis_acc: 62.1536\n",
      "D_fake_dis_acc: 62.024\n",
      "D_real_aux_loss: 0.6159586209848523\n",
      "D_fake_aux_loss: 1.2903338034560905\n",
      "Epoch: 196\n",
      "training D Loss: 0.10328510369881988\n",
      "training G Loss: 7.933711404561996\n",
      "D_real_dis_acc: 62.2528\n",
      "D_fake_dis_acc: 62.1552\n",
      "D_real_aux_loss: 0.5549663926929236\n",
      "D_fake_aux_loss: 1.4197302643509582\n",
      "Epoch: 197\n",
      "training D Loss: 0.09181354906186462\n",
      "training G Loss: 7.834763346290589\n",
      "D_real_dis_acc: 62.5024\n",
      "D_fake_dis_acc: 62.344\n",
      "D_real_aux_loss: 0.6361917680859566\n",
      "D_fake_aux_loss: 1.6898894096489996\n",
      "Epoch: 198\n",
      "training D Loss: 0.10458502545878291\n",
      "training G Loss: 7.8263930854797366\n",
      "D_real_dis_acc: 62.1328\n",
      "D_fake_dis_acc: 62.0176\n",
      "D_real_aux_loss: 0.6034840050637722\n",
      "D_fake_aux_loss: 1.4092262465503067\n",
      "Epoch: 199\n",
      "training D Loss: 0.07902508186548948\n",
      "training G Loss: 7.977672957515717\n",
      "D_real_dis_acc: 62.7008\n",
      "D_fake_dis_acc: 62.5408\n",
      "D_real_aux_loss: 0.5429997163116932\n",
      "D_fake_aux_loss: 1.131819979176484\n",
      "Epoch: 200\n",
      "training D Loss: 0.10134486393071711\n",
      "training G Loss: 7.770870175933838\n",
      "D_real_dis_acc: 62.16\n",
      "D_fake_dis_acc: 62.0432\n",
      "D_real_aux_loss: 0.6016591589957475\n",
      "D_fake_aux_loss: 1.018712646894157\n"
     ]
    }
   ],
   "source": [
    "# loss functions\n",
    "dis_criterion = nn.BCELoss()\n",
    "aux_criterion = nn.BCELoss()\n",
    "\n",
    "# training\n",
    "latent_size = 100\n",
    "BATCH_SIZE = 64\n",
    "G = Generator()\n",
    "D = Discriminator()\n",
    "G.cuda()\n",
    "D.cuda()\n",
    "\n",
    "# setup optimizer\n",
    "beta_1 = 0.5\n",
    "optimizerG = optim.Adam(G.parameters(), lr=0.0002, betas=(beta_1,0.999))\n",
    "optimizerD = optim.Adam(D.parameters(), lr=0.0002, betas=(beta_1,0.999))\n",
    "\n",
    "\n",
    "D_loss_list = []\n",
    "G_loss_list = []\n",
    "D_fake_acc_list = []\n",
    "D_real_acc_list = []\n",
    "\n",
    "D_fake_class_list = []\n",
    "D_real_class_list = []\n",
    "\n",
    "\n",
    "for epoch in range(200):\n",
    "    print(\"Epoch:\", epoch+1)\n",
    "    epoch_D_loss = 0.0\n",
    "    epoch_G_loss = 0.0\n",
    "    D_fake_acc = 0.0\n",
    "    D_real_acc = 0.0\n",
    "    D_fake_class = 0.0\n",
    "    D_real_class = 0.0\n",
    "    total_length = len(dataloader)\n",
    "\n",
    "    if (epoch+1) == 15:\n",
    "        optimizerG.param_groups[0]['lr'] /= 2\n",
    "        optimizerD.param_groups[0]['lr'] /= 2\n",
    "        print(\"learning rate change!\")\n",
    "    \n",
    "    \n",
    "    for i, batch in enumerate(dataloader):\n",
    "        if i > total_length:\n",
    "            break\n",
    "        for _ in range(1):    \n",
    "            D.zero_grad()\n",
    "            input_X = batch[0]\n",
    "            intput_class = batch[1]\n",
    "\n",
    "            #### train with real image -> ground truth = real label\n",
    "            real_image = Variable(input_X.cuda()) # use GPU \n",
    "            real_class = Variable(intput_class.type(torch.FloatTensor).cuda())\n",
    "            real_label = Variable(torch.ones((BATCH_SIZE))).cuda()\n",
    "            dis_ouput, aux_output = D(real_image)\n",
    "            D_real_dis_loss = dis_criterion(dis_ouput, real_label.view(BATCH_SIZE,1))\n",
    "            D_real_aux_loss = aux_criterion(aux_output, real_class.view(BATCH_SIZE,1))\n",
    "            D_real_acc += np.mean(((dis_ouput > 0.5).cpu().data.numpy() == real_label.cpu().data.numpy()))\n",
    "            D_real_loss = (D_real_dis_loss + D_real_aux_loss)/2\n",
    "            D_real_class += D_real_aux_loss.item()\n",
    "\n",
    "            noise = torch.randn(BATCH_SIZE, 100, 1, 1)\n",
    "            fake_class = torch.from_numpy(np.random.randint(2,size=BATCH_SIZE)).view(BATCH_SIZE,1,1,1)\n",
    "            intput_vector =Variable(torch.cat((noise,fake_class.type(torch.FloatTensor)),1)).cuda()\n",
    "\n",
    "            fake_label = Variable(torch.zeros((BATCH_SIZE))).cuda()\n",
    "            fake_class = Variable(fake_class.type(torch.FloatTensor)).cuda()\n",
    "\n",
    "            fake_image = G(intput_vector)\n",
    "            dis_output, aux_output = D(fake_image.detach())\n",
    "            D_fake_dis_loss = dis_criterion(dis_output, fake_label.view(BATCH_SIZE,1))\n",
    "            D_fake_aux_loss = aux_criterion(aux_output, fake_class.view(BATCH_SIZE,1))\n",
    "            D_fake_loss = (D_fake_dis_loss + D_fake_aux_loss)/2\n",
    "            D_fake_acc += np.mean(((dis_output > 0.5).cpu().data.numpy() == fake_label.cpu().data.numpy()))\n",
    "            D_fake_class += D_fake_aux_loss.item()\n",
    "            # update D\n",
    "            D_train_loss = D_real_loss + D_fake_loss\n",
    "            D_train_loss.backward()\n",
    "            epoch_D_loss+=(D_train_loss.item())\n",
    "\n",
    "            optimizerD.step()\n",
    "        \n",
    "        #### train Generator\n",
    "        for _ in range(2):\n",
    "            G.zero_grad()\n",
    "\n",
    "            noise = torch.randn(BATCH_SIZE, 100, 1, 1)\n",
    "            fake_class = torch.from_numpy(np.random.randint(2,size=BATCH_SIZE)).view(BATCH_SIZE,1,1,1)\n",
    "\n",
    "            intput_vector = Variable(torch.cat((noise,fake_class.type(torch.FloatTensor)),1)).cuda()\n",
    "\n",
    "            fake_class = Variable(fake_class.type(torch.FloatTensor)).cuda()\n",
    "            fake_label_for_G = Variable(torch.ones((BATCH_SIZE))).cuda()\n",
    "\n",
    "            fake_image = G(intput_vector)\n",
    "            dis_output, aux_output = D(fake_image)\n",
    "            G_dis_loss = dis_criterion(dis_output, fake_label_for_G.view(BATCH_SIZE,1))\n",
    "            G_aux_loss = aux_criterion(aux_output, fake_class.view(BATCH_SIZE,1))\n",
    "            G_train_loss = G_dis_loss + G_aux_loss\n",
    "            G_train_loss.backward()\n",
    "            optimizerG.step()\n",
    "        epoch_G_loss += (G_train_loss.item())\n",
    "    print(\"training D Loss:\",epoch_D_loss/(total_length))\n",
    "    print(\"training G Loss:\", epoch_G_loss/(total_length))\n",
    "    D_loss_list.append(epoch_D_loss/(total_length))\n",
    "    G_loss_list.append(epoch_G_loss/(total_length))\n",
    "    \n",
    "    print(\"D_real_dis_acc:\", D_real_acc/(total_length/BATCH_SIZE))\n",
    "    print(\"D_fake_dis_acc:\", D_fake_acc/(total_length/BATCH_SIZE))\n",
    "    print(\"D_real_aux_loss:\", D_real_class/(total_length/BATCH_SIZE))\n",
    "    print(\"D_fake_aux_loss:\", D_fake_class/(total_length/BATCH_SIZE))\n",
    "    D_real_acc_list.append(D_real_acc/(total_length/BATCH_SIZE))\n",
    "    D_fake_acc_list.append(D_fake_acc/(total_length/BATCH_SIZE))    \n",
    "    D_real_class_list.append(D_real_class/(total_length/BATCH_SIZE))\n",
    "    D_fake_class_list.append(D_fake_class/(total_length/BATCH_SIZE))\n",
    "    # evaluation\n",
    "    G.eval()\n",
    "    fixed_img_output = G(fixed_input)\n",
    "    G.train()\n",
    "    torchvision.utils.save_image(fixed_img_output.cpu().data, './output3/output_'+str(epoch+1)+'.jpg',nrow=10)\n",
    "    \n",
    "    torch.save(G.state_dict(), \"./checkpoint3/G_ACG2_model.pkt.\"+str(epoch+1))\n",
    "    torch.save(D.state_dict(), \"./checkpoint3/D_ACG2_model.pkt.\"+str(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 64, 64])\n",
      "torch.Size([10, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "### Load Model ###\n",
    "AC_G = Generator()\n",
    "AC_G.cuda()\n",
    "pretrained_acgan = \"./checkpoint3/G_ACG2_model.pkt.196\"\n",
    "AC_G.load_state_dict(torch.load(pretrained_acgan))\n",
    "AC_G.eval()\n",
    "\n",
    "output1 = []\n",
    "output2 = []\n",
    "random_seed = [1046, 33,45,50,60,84,169,120,1065,9093]\n",
    "for seed in random_seed[:]:\n",
    "    random.seed((seed))\n",
    "    torch.manual_seed(seed)\n",
    "    # use for random generation\n",
    "    up = np.ones(1)\n",
    "    down = np.zeros(1)\n",
    "    fixed_class = np.hstack((up,down))\n",
    "    fixed_class = torch.from_numpy(fixed_class).view(2,1,1,1).type(torch.FloatTensor)\n",
    "    fixed_noise = torch.randn(1, 100, 1, 1)\n",
    "    fixed_noise = torch.cat((fixed_noise,fixed_noise))\n",
    "    fixed_input = Variable(torch.cat((fixed_noise, fixed_class),1)).cuda()\n",
    "\n",
    "    fixed_img_output = AC_G(fixed_input)\n",
    "    \n",
    "    output1.append(fixed_img_output[0].data.unsqueeze(0))\n",
    "    output2.append(fixed_img_output[1].data.unsqueeze(0))\n",
    "\n",
    "output_pair_1 = torch.cat(output1)\n",
    "output_pair_2 = torch.cat(output2)\n",
    "print(output_pair_1.size())\n",
    "print(output_pair_2.size())\n",
    "\n",
    "output = torch.cat((output_pair_1, output_pair_2))\n",
    "    \n",
    "torchvision.utils.save_image(output, \"./seed_2/seed_\"+\"ALL\"+\".jpg\",nrow=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
